# Leaderboard

## Table of Contents
- [Object Addition](#object-addition)
- [Object Replacement](#object-replacement)
- [Object Removal](#object-removal)
- [Background Change](#background-change)
- [Style Change](#style-change)
- [Texture Change](#texture-change)
- [Action Change](#action-change)


## Object Addition
<table>
  <tr>
    <th rowspan="2">Rank</th>
    <th rowspan="2">Model</th>
    <th rowspan="2">Publication</th>
    <th rowspan="2">Dataset</th>
    <th colspan="2">LMM Score</th>
  </tr>
  <tr>
    <th>Mean&uarr;</th>
    <th>Standard Deviation &darr;</th>
  </tr>
  <tr>
    <td>1</td>
    <td><a href="https://openaccess.thecvf.com/content/CVPR2023/papers/Kawar_Imagic_Text-Based_Real_Image_Editing_With_Diffusion_Models_CVPR_2023_paper.pdf">Imagic</a></td>
    <td><a href="https://openaccess.thecvf.com/content/CVPR2023/papers/Kawar_Imagic_Text-Based_Real_Image_Editing_With_Diffusion_Models_CVPR_2023_paper.pdf">Imagic: Text-based real image editing with diffusion models (CVPR 2023)</a></td>
    <td>EditEval_v1</td>
    <td>7.80</td>
    <td>1.27</td>
  </tr>
  <tr>
    <td>2</td>
    <td><a href="https://arxiv.org/pdf/2309.03895.pdf">InstructDiffusion</a></td>
    <td><a href="https://arxiv.org/pdf/2309.03895.pdf">InstructDiffusion: A generalist modeling interface for vision tasks (CVPR 2024)</a></td>
    <td>EditEval_v1</td>
    <td>7.59</td>
    <td>1.89</td>
  </tr>
  <tr>
    <td>3</td>
    <td><a href="https://openaccess.thecvf.com/content/WACV2024/papers/Han_ProxEdit_Improving_Tuning-Free_Real_Image_Editing_With_Proximal_Guidance_WACV_2024_paper.pdf">ProxEdit</a></td>
    <td><a href="https://openaccess.thecvf.com/content/WACV2024/papers/Han_ProxEdit_Improving_Tuning-Free_Real_Image_Editing_With_Proximal_Guidance_WACV_2024_paper.pdf">ProxEdit: Improving Tuning-Free Real Image Editing With Proximal Guidance (WACV 2024)</a></td>
    <td>EditEval_v1</td>
    <td>7.06</td>
    <td>1.53</td>
  </tr>
  <tr>
    <td>4</td>
    <td><a href="https://openaccess.thecvf.com/content/CVPR2023/papers/Brooks_InstructPix2Pix_Learning_To_Follow_Image_Editing_Instructions_CVPR_2023_paper.pdf">InstructPix2Pix</a></td>
    <td><a href="https://openaccess.thecvf.com/content/CVPR2023/papers/Brooks_InstructPix2Pix_Learning_To_Follow_Image_Editing_Instructions_CVPR_2023_paper.pdf">InstructPix2Pix: Learning to follow image editing instructions (CVPR 2023)</a></td>
    <td>EditEval_v1</td>
    <td>6.88</td>
    <td>2.31</td>
  </tr>
  <tr>
    <td>5</td>
    <td><a href="https://openaccess.thecvf.com/content/ICCV2023/papers/Pan_Effective_Real_Image_Editing_with_Accelerated_Iterative_Diffusion_Inversion_ICCV_2023_paper.pdf">AIDI</a></td>
    <td><a href="https://openaccess.thecvf.com/content/ICCV2023/papers/Pan_Effective_Real_Image_Editing_with_Accelerated_Iterative_Diffusion_Inversion_ICCV_2023_paper.pdf">Effective real image editing with accelerated iterative diffusion inversion (ICCV 2023)</a></td>
    <td>EditEval_v1</td>
    <td>6.81</td>
    <td>1.79</td>
  </tr>
<tr>
  <td>6</td>
  <td><a href="https://arxiv.org/pdf/2304.06140.pdf">DDPM Inversion</a></td>
  <td><a href="https://arxiv.org/pdf/2304.06140.pdf">An edit friendly ddpm noise space: Inversion and manipulations (CVPR 2024)</a></td>
  <td>EditEval_v1</td>
  <td>6.76</td>
  <td>1.69</td>
</tr>
<tr>
  <td>7</td>
  <td><a href="https://arxiv.org/pdf/2311.16711.pdf">LEDITS++</a></td>
  <td><a href="https://arxiv.org/pdf/2311.16711.pdf">LEDITS++: Limitless Image Editing using Text-to-Image Models (CVPR 2024)</a></td>
  <td>EditEval_v1</td>
  <td>6.74</td>
  <td>1.72</td>
</tr>
<tr>
  <td>8</td>
  <td><a href="https://openaccess.thecvf.com/content/CVPR2023/papers/Wu_Uncovering_the_Disentanglement_Capability_in_Text-to-Image_Diffusion_Models_CVPR_2023_paper.pdf">DiffusionDisentanglement</a></td>
  <td><a href="https://openaccess.thecvf.com/content/CVPR2023/papers/Wu_Uncovering_the_Disentanglement_Capability_in_Text-to-Image_Diffusion_Models_CVPR_2023_paper.pdf">Uncovering the disentanglement capability in text-to-image diffusion models (CVPR 2023)</a></td>
  <td>EditEval_v1</td>
  <td>6.14</td>
  <td>1.74</td>
</tr>
</table>

## Object Replacement

<table>
  <tr>
    <th rowspan="2">Rank</th>
    <th rowspan="2">Model</th>
    <th rowspan="2">Publication</th>
    <th rowspan="2">Dataset</th>
    <th colspan="2">LMM Score</th>
  </tr>
  <tr>
    <th>Mean&uarr;</th>
    <th>Standard Deviation &darr;</th>
  </tr>
  <tr>
    <td>1</td>
    <td><a href="https://openaccess.thecvf.com/content/CVPR2023/papers/Mokady_NULL-Text_Inversion_for_Editing_Real_Images_Using_Guided_Diffusion_Models_CVPR_2023_paper.pdf">Null-Text Inversion</a></td>
    <td><a href="https://openaccess.thecvf.com/content/CVPR2023/papers/Mokady_NULL-Text_Inversion_for_Editing_Real_Images_Using_Guided_Diffusion_Models_CVPR_2023_paper.pdf">Null-text inversion for editing real images using guided diffusion models (CVPR 2023)</a></td>
    <td>EditEval_v1</td>
    <td>8.15</td>
    <td>0.80</td>
  </tr>
  <tr>
    <td>2</td>
    <td><a href="https://openaccess.thecvf.com/content/ICCV2023/papers/Pan_Effective_Real_Image_Editing_with_Accelerated_Iterative_Diffusion_Inversion_ICCV_2023_paper.pdf">AIDI</a></td>
    <td><a href="https://openaccess.thecvf.com/content/ICCV2023/papers/Pan_Effective_Real_Image_Editing_with_Accelerated_Iterative_Diffusion_Inversion_ICCV_2023_paper.pdf">Effective real image editing with accelerated iterative diffusion inversion (ICCV 2023)</a></td>
    <td>EditEval_v1</td>
    <td>7.84</td>
    <td>1.00</td>
  </tr>
  <tr>
    <td>3</td>
    <td><a href="https://openaccess.thecvf.com/content/CVPR2023/papers/Wu_Uncovering_the_Disentanglement_Capability_in_Text-to-Image_Diffusion_Models_CVPR_2023_paper.pdf">DiffusionDisentanglement</a></td>
    <td><a href="https://openaccess.thecvf.com/content/CVPR2023/papers/Wu_Uncovering_the_Disentanglement_Capability_in_Text-to-Image_Diffusion_Models_CVPR_2023_paper.pdf">Uncovering the disentanglement capability in text-to-image diffusion models (CVPR 2023)</a></td>
    <td>EditEval_v1</td>
    <td>7.66</td>
    <td>1.41</td>
  </tr>
  <tr>
    <td>4</td>
    <td><a href="https://openaccess.thecvf.com/content/WACV2024/papers/Han_ProxEdit_Improving_Tuning-Free_Real_Image_Editing_With_Proximal_Guidance_WACV_2024_paper.pdf">ProxEdit</a></td>
    <td><a href="https://openaccess.thecvf.com/content/WACV2024/papers/Han_ProxEdit_Improving_Tuning-Free_Real_Image_Editing_With_Proximal_Guidance_WACV_2024_paper.pdf">ProxEdit: Improving Tuning-Free Real Image Editing With Proximal Guidance (WACV 2024)</a></td>
    <td>EditEval_v1</td>
    <td>7.53</td>
    <td>1.63</td>
  </tr>
  <tr>
    <td>5</td>
    <td><a href="https://arxiv.org/pdf/2311.16711.pdf">LEDITS++</a></td>
    <td><a href="https://arxiv.org/pdf/2311.16711.pdf">LEDITS++: Limitless Image Editing using Text-to-Image Models (CVPR 2024)</a></td>
      <td>EditEval_v1</td>
    <td>7.41</td>
    <td>1.86</td>
  </tr>
  <tr>
    <td>6</td>
    <td><a href="https://openaccess.thecvf.com/content/CVPR2023/papers/Kawar_Imagic_Text-Based_Real_Image_Editing_With_Diffusion_Models_CVPR_2023_paper.pdf">Imagic</a></td>
    <td><a href="https://openaccess.thecvf.com/content/CVPR2023/papers/Kawar_Imagic_Text-Based_Real_Image_Editing_With_Diffusion_Models_CVPR_2023_paper.pdf">Imagic: Text-based real image editing with diffusion models (CVPR 2023)</a></td>
    <td>EditEval_v1</td>
    <td>7.22</td>
    <td>1.65</td>
  </tr>
  <tr>
    <td>7</td>
    <td><a href="https://arxiv.org/pdf/2309.03895.pdf">InstructDiffusion</a></td>
    <td><a href="https://arxiv.org/pdf/2309.03895.pdf">InstructDiffusion: A generalist modeling interface for vision tasks (CVPR 2024)</a></td>
    <td>EditEval_v1</td>
    <td>6.55</td>
    <td>1.46</td>
  </tr>
  <tr>
    <td>8</td>
    <td><a href="https://openaccess.thecvf.com/content/CVPR2023/papers/Brooks_InstructPix2Pix_Learning_To_Follow_Image_Editing_Instructions_CVPR_2023_paper.pdf">InstructPix2Pix</a></td>
    <td><a href="https://openaccess.thecvf.com/content/CVPR2023/papers/Brooks_InstructPix2Pix_Learning_To_Follow_Image_Editing_Instructions_CVPR_2023_paper.pdf">InstructPix2Pix: Learning to follow image editing instructions (CVPR 2023)</a></td>
    <td>EditEval_v1</td>
    <td>5.00</td>
    <td>1.95</td>
  </tr>
</table>

## Object Removal
<table>
  <tr>
    <th rowspan="2">Rank</th>
    <th rowspan="2">Model</th>
    <th rowspan="2">Publication</th>
    <th rowspan="2">Dataset</th>
    <th colspan="2">LMM Score</th>
  </tr>
  <tr>
    <th>Mean&uarr;</th>
    <th>Standard Deviation &darr;</th>
  </tr>
  <tr>
    <td>1</td>
    <td><a href="https://arxiv.org/pdf/2311.16711.pdf">LEDITS++</a></td>
    <td><a href="https://arxiv.org/pdf/2311.16711.pdf">LEDITS++: Limitless Image Editing using Text-to-Image Models (CVPR 2024)</a></td>
    <td>EditEval_v1</td>
    <td>8.65</td>
    <td>1.29</td>
  </tr>
  <tr>
    <td>2</td>
    <td><a href="https://openaccess.thecvf.com/content/WACV2024/papers/Han_ProxEdit_Improving_Tuning-Free_Real_Image_Editing_With_Proximal_Guidance_WACV_2024_paper.pdf">ProxEdit</a></td>
    <td><a href="https://openaccess.thecvf.com/content/WACV2024/papers/Han_ProxEdit_Improving_Tuning-Free_Real_Image_Editing_With_Proximal_Guidance_WACV_2024_paper.pdf">ProxEdit: Improving Tuning-Free Real Image Editing With Proximal Guidance (WACV 2024)</a></td>
    <td>EditEval_v1</td>
    <td>7.75</td>
    <td>1.26</td>
  </tr>
  <tr>
    <td>3</td>
    <td><a href="https://arxiv.org/pdf/2309.03895.pdf">InstructDiffusion</a></td>
    <td><a href="https://arxiv.org/pdf/2309.03895.pdf">InstructDiffusion: A generalist modeling interface for vision tasks (CVPR 2024)</a></td>
    <td>EditEval_v1</td>
    <td>7.48</td>
    <td>1.68</td>
  </tr>
  <tr>
    <td>4</td>
    <td><a href="https://openaccess.thecvf.com/content/ICCV2023/papers/Pan_Effective_Real_Image_Editing_with_Accelerated_Iterative_Diffusion_Inversion_ICCV_2023_paper.pdf">AIDI</a></td>
    <td><a href="https://openaccess.thecvf.com/content/ICCV2023/papers/Pan_Effective_Real_Image_Editing_with_Accelerated_Iterative_Diffusion_Inversion_ICCV_2023_paper.pdf">Effective real image editing with accelerated iterative diffusion inversion (ICCV 2023)</a></td>
    <td>EditEval_v1</td>
    <td>6.72</td>
    <td>1.53</td>
  </tr>
  <tr>
    <td>5</td>
    <td><a href="https://arxiv.org/pdf/2304.03246.pdf">Inst-Inpaint</a></td>
    <td><a href="https://arxiv.org/pdf/2304.03246.pdf">Inst-Inpaint: Instructing to Remove Objects with Diffusion Models (arXiv 2023)</a></td>
    <td>EditEval_v1</td>
    <td>6.10</td>
    <td>1.54</td>
  </tr>
</table>

## Background Change

<table>
  <tr>
    <th rowspan="2">Rank</th>
    <th rowspan="2">Model</th>
    <th rowspan="2">Publication</th>
    <th rowspan="2">Dataset</th>
    <th colspan="2">LMM Score</th>
  </tr>
  <tr>
    <th>Mean&uarr;</th>
    <th>Standard Deviation &darr;</th>
  </tr>
  <tr>
    <td>1</td>
    <td><a href="https://openaccess.thecvf.com/content/CVPR2023/papers/Mokady_NULL-Text_Inversion_for_Editing_Real_Images_Using_Guided_Diffusion_Models_CVPR_2023_paper.pdf">Null-Text Inversion</a></td>
    <td><a href="https://openaccess.thecvf.com/content/CVPR2023/papers/Mokady_NULL-Text_Inversion_for_Editing_Real_Images_Using_Guided_Diffusion_Models_CVPR_2023_paper.pdf">Null-text inversion for editing real images using guided diffusion models (CVPR 2023)</a></td>
    <td>EditEval_v1</td>
    <td>7.28</td>
    <td>1.17</td>
  </tr>
  <tr>
    <td>2</td>
    <td><a href="https://arxiv.org/pdf/2311.16711.pdf">LEDITS++</a></td>
    <td><a href="https://arxiv.org/pdf/2311.16711.pdf">LEDITS++: Limitless Image Editing using Text-to-Image Models (CVPR 2024)</a></td>
    <td>EditEval_v1</td>
    <td>6.91</td>
    <td>0.97</td>
  </tr>
  <tr>
    <td>4</td>
    <td><a href="https://openaccess.thecvf.com/content/CVPR2023/papers/Brooks_InstructPix2Pix_Learning_To_Follow_Image_Editing_Instructions_CVPR_2023_paper.pdf">InstructPix2Pix</a></td>
    <td><a href="https://openaccess.thecvf.com/content/CVPR2023/papers/Brooks_InstructPix2Pix_Learning_To_Follow_Image_Editing_Instructions_CVPR_2023_paper.pdf">InstructPix2Pix: Learning to follow image editing instructions (CVPR 2023)</a></td>
    <td>EditEval_v1</td>
    <td>6.51</td>
    <td>2.49</td>
  </tr>
  <tr>
    <td>3</td>
    <td><a href="https://openaccess.thecvf.com/content/WACV2024/papers/Han_ProxEdit_Improving_Tuning-Free_Real_Image_Editing_With_Proximal_Guidance_WACV_2024_paper.pdf">ProxEdit</a></td>
    <td><a href="https://openaccess.thecvf.com/content/WACV2024/papers/Han_ProxEdit_Improving_Tuning-Free_Real_Image_Editing_With_Proximal_Guidance_WACV_2024_paper.pdf">ProxEdit: Improving Tuning-Free Real Image Editing With Proximal Guidance (WACV 2024)</a></td>
    <td>EditEval_v1</td>
    <td>6.35</td>
    <td>0.78</td>
  </tr>
 <tr>
    <td>6</td>
    <td><a href="https://openaccess.thecvf.com/content/ICCV2023/papers/Hertz_Delta_Denoising_Score_ICCV_2023_paper.pdf">DDS</a></td>
    <td><a href="https://openaccess.thecvf.com/content/ICCV2023/papers/Hertz_Delta_Denoising_Score_ICCV_2023_paper.pdf">Delta denoising score (ICCV 2023)</a></td>
    <td>EditEval_v1</td>
    <td>6.17</td>
    <td>0.81</td>
  </tr>
  <tr>
    <td>7</td>
    <td><a href="https://openaccess.thecvf.com/content/ICCV2023/papers/Pan_Effective_Real_Image_Editing_with_Accelerated_Iterative_Diffusion_Inversion_ICCV_2023_paper.pdf">AIDI</a></td>
    <td><a href="https://openaccess.thecvf.com/content/ICCV2023/papers/Pan_Effective_Real_Image_Editing_with_Accelerated_Iterative_Diffusion_Inversion_ICCV_2023_paper.pdf">Effective real image editing with accelerated iterative diffusion inversion (ICCV 2023)</a></td>
    <td>EditEval_v1</td>
    <td>5.95</td>
    <td>2.34</td>
  </tr>
  <tr>
    <td>8</td>
    <td><a href="https://openaccess.thecvf.com/content/CVPR2023/html/Wallace_EDICT_Exact_Diffusion_Inversion_via_Coupled_Transformations_CVPR_2023_paper.html">EDICT</a></td>
    <td><a href="https://openaccess.thecvf.com/content/CVPR2023/html/Wallace_EDICT_Exact_Diffusion_Inversion_via_Coupled_Transformations_CVPR_2023_paper.html">EDICT: Efficient Diffusion for Image Composition and Transformation (CVPR 2023)</a></td>
    <td>EditEval_v1</td>
    <td>5.01</td>
    <td>1.94</td>
  </tr>
  <tr>
    <td>5</td>
    <td><a href="https://openaccess.thecvf.com/content/CVPR2023/papers/Zhang_SINE_SINgle_Image_Editing_With_Text-to-Image_Diffusion_Models_CVPR_2023_paper.pdf">SINE</a></td>
    <td><a href="https://openaccess.thecvf.com/content/CVPR2023/papers/Zhang_SINE_SINgle_Image_Editing_With_Text-to-Image_Diffusion_Models_CVPR_2023_paper.pdf">Sine: Single image editing with text-to-image diffusion models (CVPR 2023)</a></td>
    <td>EditEval_v1</td>
    <td>3.02</td>
    <td>1.83</td>
  </tr>
</table>

## Style Change

<table>
  <tr>
    <th rowspan="2">Rank</th>
    <th rowspan="2">Model</th>
    <th rowspan="2">Publication</th>
    <th rowspan="2">Dataset</th>
    <th colspan="2">LMM Score</th>
  </tr>
  <tr>
    <th>Mean&uarr;</th>
    <th>Standard Deviation &darr;</th>
  </tr>
  <tr>
    <td>1</td>
    <td><a href="https://openaccess.thecvf.com/content/CVPR2023/papers/Brooks_InstructPix2Pix_Learning_To_Follow_Image_Editing_Instructions_CVPR_2023_paper.pdf">InstructPix2Pix</a></td>
    <td><a href="https://openaccess.thecvf.com/content/CVPR2023/papers/Brooks_InstructPix2Pix_Learning_To_Follow_Image_Editing_Instructions_CVPR_2023_paper.pdf">InstructPix2Pix: Learning to follow image editing instructions (CVPR 2023)</a></td>
    <td>EditEval_v1</td>
    <td>8.21</td>
    <td>0.40</td>
  </tr>
  <tr>
    <td>2</td>
    <td><a href="https://arxiv.org/pdf/2309.03895.pdf">InstructDiffusion</a></td>
    <td><a href="https://arxiv.org/pdf/2309.03895.pdf">InstructDiffusion: A generalist modeling interface for vision tasks (CVPR 2024)</a></td>
    <td>EditEval_v1</td>
    <td>7.41</td>
    <td>0.66</td>
  </tr>
  <tr>
    <td>3</td>
    <td><a href="https://openaccess.thecvf.com/content/CVPR2023/papers/Kawar_Imagic_Text-Based_Real_Image_Editing_With_Diffusion_Models_CVPR_2023_paper.pdf">Imagic</a></td>
    <td><a href="https://openaccess.thecvf.com/content/CVPR2023/papers/Kawar_Imagic_Text-Based_Real_Image_Editing_With_Diffusion_Models_CVPR_2023_paper.pdf">Imagic: Text-based real image editing with diffusion models (CVPR 2023)</a></td>
    <td>EditEval_v1</td>
    <td>7.26</td>
    <td>1.25</td>
  </tr>
  <tr>
    <td>4</td>
    <td><a href="https://openaccess.thecvf.com/content/CVPR2023/papers/Mokady_NULL-Text_Inversion_for_Editing_Real_Images_Using_Guided_Diffusion_Models_CVPR_2023_paper.pdf">Null-Text Inversion</a></td>
    <td><a href="https://openaccess.thecvf.com/content/CVPR2023/papers/Mokady_NULL-Text_Inversion_for_Editing_Real_Images_Using_Guided_Diffusion_Models_CVPR_2023_paper.pdf">Null-text inversion for editing real images using guided diffusion models (CVPR 2023)</a></td>
    <td>EditEval_v1</td>
    <td>7.16</td>
    <td>0.90</td>
  </tr>
  <tr>
    <td>5</td>
    <td><a href="https://arxiv.org/pdf/2304.06140.pdf">DDPM Inversion</a></td>
    <td><a href="https://arxiv.org/pdf/2304.06140.pdf">An edit friendly ddpm noise space: Inversion and manipulations (CVPR 2024)</a></td>
    <td>EditEval_v1</td>
    <td>7.08</td>
    <td>0.81</td>
  </tr>
  <tr>
    <td>6</td>
    <td><a href="https://openaccess.thecvf.com/content/ICCV2023/papers/Pan_Effective_Real_Image_Editing_with_Accelerated_Iterative_Diffusion_Inversion_ICCV_2023_paper.pdf">AIDI</a></td>
    <td><a href="https://openaccess.thecvf.com/content/ICCV2023/papers/Pan_Effective_Real_Image_Editing_with_Accelerated_Iterative_Diffusion_Inversion_ICCV_2023_paper.pdf">Effective real image editing with accelerated iterative diffusion inversion (ICCV 2023)</a></td>
    <td>EditEval_v1</td>
    <td>6.99</td>
    <td>1.07</td>
  </tr>
  <tr>
    <td>8</td>
    <td><a href="https://arxiv.org/pdf/2311.16711.pdf">LEDITS++</a></td>
    <td><a href="https://arxiv.org/pdf/2311.16711.pdf">LEDITS++: Limitless Image Editing using Text-to-Image Models (CVPR 2024)</a></td>
    <td>EditEval_v1</td>
    <td>6.86</td>
    <td>1.20</td>
  </tr>
  <tr>
    <td>7</td>
    <td><a href="https://openaccess.thecvf.com/content/WACV2024/papers/Han_ProxEdit_Improving_Tuning-Free_Real_Image_Editing_With_Proximal_Guidance_WACV_2024_paper.pdf">ProxEdit</a></td>
    <td><a href="https://openaccess.thecvf.com/content/WACV2024/papers/Han_ProxEdit_Improving_Tuning-Free_Real_Image_Editing_With_Proximal_Guidance_WACV_2024_paper.pdf">ProxEdit: Improving Tuning-Free Real Image Editing With Proximal Guidance (WACV 2024)</a></td>
    <td>EditEval_v1</td>
    <td>6.80</td>
    <td>1.07</td>
  </tr>
</table>

## Texture Change
<table>
  <tr>
    <th rowspan="2">Rank</th>
    <th rowspan="2">Model</th>
    <th rowspan="2">Publication</th>
    <th rowspan="2">Dataset</th>
    <th colspan="2">LMM Score</th>
  </tr>
  <tr>
    <th>Mean&uarr;</th>
    <th>Standard Deviation &darr;</th>
  </tr>
  <tr>
    <td>1</td>
    <td><a href="https://arxiv.org/pdf/2309.03895.pdf">InstructDiffusion</a></td>
    <td><a href="https://arxiv.org/pdf/2309.03895.pdf">InstructDiffusion: A generalist modeling interface for vision tasks (CVPR 2024)</a></td>
    <td>EditEval_v1</td>
    <td>7.13</td>
    <td>1.83</td>
  </tr>
  <tr>
    <td>2</td>
    <td><a href="https://openaccess.thecvf.com/content/CVPR2023/papers/Mokady_NULL-Text_Inversion_for_Editing_Real_Images_Using_Guided_Diffusion_Models_CVPR_2023_paper.pdf">Null-Text Inversion</a></td>
    <td><a href="https://openaccess.thecvf.com/content/CVPR2023/papers/Mokady_NULL-Text_Inversion_for_Editing_Real_Images_Using_Guided_Diffusion_Models_CVPR_2023_paper.pdf">Null-text inversion for editing real images using guided diffusion models (CVPR 2023)</a></td>
    <td>EditEval_v1</td>
    <td>6.82</td>
    <td>1.44</td>
  </tr>
  <tr>
    <td>3</td>
    <td><a href="https://openaccess.thecvf.com/content/CVPR2023/html/Wu_Uncovering_the_Disentanglement_Capability_in_Text-to-Image_Diffusion_Models_CVPR_2023_paper.html">DiffusionDisentanglement</a></td>
    <td><a href="https://openaccess.thecvf.com/content/CVPR2023/html/Wu_Uncovering_the_Disentanglement_Capability_in_Text-to-Image_Diffusion_Models_CVPR_2023_paper.html">Uncovering the Disentanglement Capability in Text-to-Image Diffusion Models (CVPR 2023)</a></td>
    <td>EditEval_v1</td>
    <td>6.78</td>
    <td>1.07</td>
  </tr>
  <tr>
    <td>4</td>
    <td><a href="https://openaccess.thecvf.com/content/CVPR2023/html/Tumanyan_Plug-and-Play_Diffusion_Features_for_Text-Driven_Image-to-Image_Translation_CVPR_2023_paper.html">PnP</a></td>
    <td><a href="https://openaccess.thecvf.com/content/CVPR2023/html/Tumanyan_Plug-and-Play_Diffusion_Features_for_Text-Driven_Image-to-Image_Translation_CVPR_2023_paper.html">Plug-and-play diffusion features for text-driven image-to-image translation (CVPR 2023)</a></td>
    <td>EditEval_v1</td>
    <td>6.63</td>
    <td>1.18</td>
  </tr>
  <tr>
    <td>5</td>
    <td><a href="https://openaccess.thecvf.com/content/ICCV2023/html/Wu_A_Latent_Space_of_Stochastic_Diffusion_Models_for_Zero-Shot_Image_ICCV_2023_paper.html">CycleDiffusion</a></td>
    <td><a href="https://openaccess.thecvf.com/content/ICCV2023/html/Wu_A_Latent_Space_of_Stochastic_Diffusion_Models_for_Zero-Shot_Image_ICCV_2023_paper.html">A latent space of stochastic diffusion models for zero-shot image editing and guidance (ICCV 2023)</a></td>
    <td>EditEval_v1</td>
    <td>6.55</td>
    <td>1.00</td>
  </tr>
  <tr>
    <td>6</td>
    <td><a href="https://openaccess.thecvf.com/content/CVPR2023/papers/Brooks_InstructPix2Pix_Learning_To_Follow_Image_Editing_Instructions_CVPR_2023_paper.pdf">InstructPix2Pix</a></td>
    <td><a href="https://openaccess.thecvf.com/content/CVPR2023/papers/Brooks_InstructPix2Pix_Learning_To_Follow_Image_Editing_Instructions_CVPR_2023_paper.pdf">InstructPix2Pix: Learning to follow image editing instructions (CVPR 2023)</a></td>
    <td>EditEval_v1</td>
    <td>6.10</td>
    <td>1.41</td>
  </tr>
  <tr>
    <td>7</td>
    <td><a href="https://arxiv.org/abs/2306.09869">Energy-Based Cross Attention</a></td>
    <td><a href="https://arxiv.org/abs/2306.09869">Energy-Based Cross Attention for Bayesian Context Update in Text-to-Image Diffusion Models (NeurIPS 2023)</a></td>
    <td>EditEval_v1</td>
    <td>5.98</td>
    <td>0.75</td>
  </tr>
  <tr>
    <td>8</td>
    <td><a href="https://openaccess.thecvf.com/content/CVPR2023/papers/Kawar_Imagic_Text-Based_Real_Image_Editing_With_Diffusion_Models_CVPR_2023_paper.pdf">Imagic</a></td>
    <td><a href="https://openaccess.thecvf.com/content/CVPR2023/papers/Kawar_Imagic_Text-Based_Real_Image_Editing_With_Diffusion_Models_CVPR_2023_paper.pdf">Imagic: Text-based real image editing with diffusion models (CVPR 2023)</a></td>
    <td>EditEval_v1</td>
    <td>5.57</td>
    <td>1.49</td>
  </tr>
</table>

## Action Change

<table>
  <tr>
    <th rowspan="2">Rank</th>
    <th rowspan="2">Model</th>
    <th rowspan="2">Publication</th>
    <th rowspan="2">Dataset</th>
    <th colspan="2">LMM Score</th>
  </tr>
  <tr>
    <th>Mean&uarr;</th>
    <th>Standard Deviation &darr;</th>
  </tr>
  <tr>
    <td>1</td>
    <td><a href="https://openaccess.thecvf.com/content/CVPR2023/papers/Kawar_Imagic_Text-Based_Real_Image_Editing_With_Diffusion_Models_CVPR_2023_paper.pdf">Imagic</a></td>
    <td><a href="https://openaccess.thecvf.com/content/CVPR2023/papers/Kawar_Imagic_Text-Based_Real_Image_Editing_With_Diffusion_Models_CVPR_2023_paper.pdf">Imagic: Text-based real image editing with diffusion models (CVPR 2023)</a></td>
    <td>EditEval_v1</td>
    <td>6.97</td>
    <td>0.80</td>
  </tr>
  <tr>
    <td>2</td>
    <td><a href="https://arxiv.org/abs/2309.10556">Forgedit</a></td>
    <td><a href="https://arxiv.org/abs/2309.10556">Forgedit: Text Guided Image Editing via Learning and Forgetting (arXiv 2023)</a></td>
    <td>EditEval_v1</td>
    <td>6.38</td>
    <td>0.87</td>
  </tr>
  <tr>
    <td>3</td>
    <td><a href="https://arxiv.org/abs/2304.08465">MasaCtrl</a></td>
    <td><a href="https://arxiv.org/abs/2304.08465">MasaCtrl: Tuning-Free Mutual Self-Attention Control for Consistent Image Synthesis and Editing (ICCV 2023)</a></td>
    <td>EditEval_v1</td>
    <td>6.55</td>
    <td>1.16</td>
  </tr>
  <tr>
    <td>4</td>
    <td><a href="https://arxiv.org/abs/2312.14611">TIC</a></td>
    <td><a href="https://arxiv.org/abs/2312.14611">Tuning-Free Inversion-Enhanced Control for Consistent Image Editing (arXiv 2023)</a></td>
    <td>EditEval_v1</td>
    <td>6.20</td>
    <td>1.70</td>
  </tr>
</table>
